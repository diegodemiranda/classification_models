{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsGrptBauXuwnfPLSJIFml",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diegodemiranda/classification_models/blob/main/apple_quality/apple_quality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxBesFy_AdGX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Lê um arquivo CSV especificado por file_path usando a biblioteca pandas.\n",
        "# O dataset está balanceado e possui 1996 resultados 'bad' e 2004 'good'.\n",
        "def read_csv_file(file_path):\n",
        "    try:\n",
        "        data = pd.read_csv(file_path)\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found.\")\n",
        "    except Exception as e:\n",
        "        print(\"Error: \", e)\n",
        "        return None\n",
        "\n",
        "\n",
        "def treat_dataset(df):\n",
        "    # Realiza o pré-processamento dos dados.\n",
        "    # Mapeamento dos valores 'good' e 'bad' para 1 e 0, respectivamente.\n",
        "    df['Quality'] = df['Quality'].replace({'good': 1, 'bad': 0})\n",
        "\n",
        "    # Remoção de linhas com valores ausentes\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # Conversão dos tipos de dados das colunas 'Acidity' e 'Quality'.\n",
        "    df['Acidity'] = df['Acidity'].astype(float)\n",
        "    df['Quality'] = df['Quality'].astype(int)\n",
        "\n",
        "    df.info()\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Recebe um DataFrame df contendo os dados e um parâmetro k para o algoritmo k-NN.\n",
        "def knn_tests(df, k):\n",
        "    # Divide os dados em atributos (variáveis independentes) x e rótulos (variável dependente) y.\n",
        "    x = df.drop(columns=['A_id', 'Quality'])\n",
        "    y = df['Quality']\n",
        "\n",
        "    # Normaliza os dados no intervalo [0, 1] com a normalização Min-Max.\n",
        "    x = (x - x.min()) / (x.max() - x.min())\n",
        "    normal = x.join(y)\n",
        "    print(\"normalized matrix:\")\n",
        "    print(normal)\n",
        "\n",
        "    # Calcula o tamanho do conjunto de dados e o divide em dados de treinamento e teste.\n",
        "    # O resultado é convertido para um número inteiro usando a função int().\n",
        "\n",
        "    train_size = int((80 / 100) * len(df))\n",
        "    x_train, x_test = x[:train_size], x[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "    # Implementa o algoritmo k-NN para fazer previsões no conjunto de teste. Essas previsões são baseadas nos\n",
        "    # rótulos dos k vizinhos mais próximos para cada amostra no conjunto de teste, utilizando a maioria de\n",
        "    # votos para determinar a classe prevista.\n",
        "    predictions = []\n",
        "    # Inicia um loop que percorre cada amostra no conjunto de teste.\n",
        "    for i in range(len(x_test)):\n",
        "        # Calcula as distâncias entre a amostra atual do conjunto de teste e todas as amostras no conjunto de\n",
        "        # treinamento. Isso é feito usando a distância euclidiana, que é a raiz quadrada da soma dos quadrados das\n",
        "        # diferenças entre os atributos de cada amostra.\n",
        "        distances = np.sqrt(np.sum((x_train - x_test.iloc[i]) ** 2, axis=1))\n",
        "        # Identifica os índices das k amostras mais próximas no conjunto de treinamento, com base nas menores\n",
        "        # distâncias calculadas. Isso é feito ordenando as distâncias e selecionando os índices dos k primeiros\n",
        "        # elementos do array ordenado.\n",
        "        nearest_neighbors = distances.argsort()[:k]\n",
        "        # Obtém os rótulos correspondentes às amostras mais próximas encontradas no conjunto de treinamento.\n",
        "        nearest_labels = y_train.iloc[nearest_neighbors]\n",
        "        # Determina o rótulo mais comum entre os vizinhos mais próximos. Isso é feito calculando a moda dos rótulos.\n",
        "        most_common_label = nearest_labels.mode()[0]\n",
        "        # Adiciona a previsão (rótulo mais comum) para a amostra atual à lista de previsões.\n",
        "        predictions.append(most_common_label)\n",
        "\n",
        "    # Calcula e escreve a matriz de confusão e os resultados obtidos para cada métrica.\n",
        "    print(\"Confusion matrix:\")\n",
        "    conf_matrix = confusion_matrix(y_test, predictions)\n",
        "    # Calcula a precisão do modelo, que é a proporção de todas as previsões corretas\n",
        "    # (verdadeiros positivos e verdadeiros negativos) em relação ao número total de amostras.\n",
        "    accuracy = (conf_matrix[0][0] + conf_matrix[1][1]) / (\n",
        "            conf_matrix[0][0] + conf_matrix[1][1] + conf_matrix[1][0] + conf_matrix[0][1])\n",
        "\n",
        "    # Calcula a precisão, que é a proporção de verdadeiros positivos em relação ao total de previsões positivas\n",
        "    # (verdadeiros positivos mais falsos positivos). Isso mede a capacidade do modelo de classificar\n",
        "    # corretamente as amostras como positivas.\n",
        "    precision = conf_matrix[0][0] / (conf_matrix[0][0] + conf_matrix[1][0])\n",
        "\n",
        "    # Calcula a sensibilidade, também conhecida como recall, que é a proporção de verdadeiros positivos em relação ao\n",
        "    # total de amostras verdadeiramente positivas (verdadeiros positivos mais falsos negativos).\n",
        "    # Isso mede a capacidade do modelo de identificar corretamente todas as amostras positivas.\n",
        "    recall = conf_matrix[0][0] / (conf_matrix[0][0] + conf_matrix[0][1])\n",
        "\n",
        "    # Calcula a especificidade, que é a proporção de verdadeiros negativos em relação ao total de amostras\n",
        "    # verdadeiramente negativas (verdadeiros negativos mais falsos positivos). Isso mede a capacidade do modelo\n",
        "    # de identificar corretamente todas as amostras negativas.\n",
        "    specificity = conf_matrix[1][1] / (conf_matrix[1][1] + conf_matrix[1][0])\n",
        "\n",
        "    # recall == valor preditivo positivo         sensibilidade == precision\n",
        "    measuref = (2 * (precision * recall)) / (precision + recall)\n",
        "\n",
        "    print(conf_matrix)\n",
        "    print(\"Accuracy:\", ((predictions == y_test).mean() * 100), \"%\")\n",
        "    print(\"Precision: \", precision * 100, \" %\")\n",
        "    print(\"Recall: \", recall * 100, \" %\")\n",
        "    print(\"Specificity: \", specificity * 100, \" %\")\n",
        "    print(\"Measure-F: \", measuref * 100, \" %\")\n",
        "\n",
        "    # Retorna as previsões feitas pelo modelo.\n",
        "    return predictions, conf_matrix, accuracy, precision, recall, specificity, measuref\n",
        "\n",
        "\n",
        "def call_knn_tests_with_column_exclusion(df, k):\n",
        "    # Obtém todas as colunas, removendo as colunas 'A_id' e 'Quality' da lista.\n",
        "    columns_to_exclude = df.columns.difference(['A_id', 'Quality'])\n",
        "\n",
        "    results = []\n",
        "    # Inicia um loop que itera sobre cada coluna a ser excluída do DataFrame.\n",
        "    for column in columns_to_exclude:\n",
        "        print(\"\\nExcluindo a coluna:\", column)\n",
        "        # Chama a função knn_tests que executa os testes sem a coluna atualmente excluída.\n",
        "        predictions, conf_matrix, accuracy, precision, recall, specificity, measuref = (\n",
        "            knn_tests(df.drop(columns=[column]), k))\n",
        "        # Adiciona os resultados dos testes à lista results, incluindo o nome da coluna excluída,\n",
        "        # a matriz de confusão e descompacta a tupla retornada pela função em várias variáveis individuais.\n",
        "        results.append((column, conf_matrix, accuracy, precision, recall, specificity, measuref))\n",
        "    # Abre um arquivo de texto chamado 'knn_results.txt' em modo de escrita e escreve as informações a seguir para\n",
        "    # cada iteração.\n",
        "    with open('knn_results.txt', 'w') as file:\n",
        "        for column, conf_matrix, accuracy, precision, recall, specificity, measuref in results:\n",
        "            file.write(f\"Column removed: ({column}) \\n\")\n",
        "            file.write(\"Confusion matrix:\\n\")\n",
        "            for row in conf_matrix:\n",
        "                file.write(f\"{row}\\n\")\n",
        "            file.write(f\"Accuracy: {accuracy * 100} %\\n\")\n",
        "            file.write(f\"Precision: {precision * 100} %\\n\")\n",
        "            file.write(f\"Recall: {recall * 100} %\\n\")\n",
        "            file.write(f\"Specificity: {specificity * 100} %\\n\")\n",
        "            file.write(f\"Measure-F: {measuref * 100} %\\n\")\n",
        "            file.write(\"\\n\")\n",
        "\n",
        "    # Abre o arquivo 'knn_results.txt' usando o aplicativo padrão do sistema operacional.\n",
        "    os.system('open knn_results.txt')\n",
        "\n",
        "\n",
        "def plot_conf_matrix(conf_matrix):\n",
        "    # Plota a matriz de confusão\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Samples\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Define o caminho do arquivo CSV contendo os dados das maçãs. Chama a função read_csv_file() para ler os dados.\n",
        "def main():\n",
        "    file_path = 'apple_quality.csv'\n",
        "    apples = read_csv_file(file_path)\n",
        "    k = 11\n",
        "    # Se os dados forem lidos com sucesso, chama a função treat_dataset() para pré-processá-los e, em\n",
        "    # seguida, chama a função knn_tests() para realizar o teste com o algoritmo KNN.\n",
        "    if apples is not None:\n",
        "        apples = treat_dataset(apples)\n",
        "        predictions, conf_matrix, accuracy, precision, recall, specificity, measuref = knn_tests(apples, k)\n",
        "        call_knn_tests_with_column_exclusion(apples, k)\n",
        "        plot_conf_matrix(conf_matrix)\n",
        "\n",
        "\n",
        "# Garante que o código dentro deste bloco só será executado se o script for executado diretamente e não importado\n",
        "# como um módulo em outro script. Isso é uma boa prática em Python para modularizar o código e evitar que\n",
        "# blocos de código sejam executados acidentalmente ao importar um módulo.\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}